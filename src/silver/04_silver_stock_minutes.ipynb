{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","from delta.tables import DeltaTable\n","\n","# Load bronze table\n","bronze_df = spark.table(\"bronze_stock_minutes\")\n","\n","# Cast fields and normalize schema\n","silver_df = (\n","    bronze_df\n","    .withColumn(\"timestamp\", F.to_timestamp(\"Datetime\"))\n","    .withColumn(\"open\", F.col(\"Open\").cast(\"double\"))\n","    .withColumn(\"high\", F.col(\"High\").cast(\"double\"))\n","    .withColumn(\"low\", F.col(\"Low\").cast(\"double\"))\n","    .withColumn(\"close\", F.col(\"Close\").cast(\"double\"))\n","    .withColumn(\"volume\", F.col(\"Volume\").cast(\"long\"))\n","    .withColumn(\"ticker\", F.col(\"Ticker\"))\n",")\n","\n","# Deduplicate by ticker + timestamp\n","window_spec = Window.partitionBy(\"ticker\", \"timestamp\").orderBy(F.lit(1))\n","\n","silver_df = (\n","    silver_df\n","    .withColumn(\"row_num\", F.row_number().over(window_spec))\n","    .filter(F.col(\"row_num\") == 1)\n","    .drop(\"row_num\")\n",")\n","\n","# Add ingestion timestamp and define final column order\n","silver_df = (\n","    silver_df\n","    .withColumn(\"ingestion_time\", F.current_timestamp())\n","    .select(\"ticker\", \"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"ingestion_time\")\n",")\n","\n","# Define target table name\n","silver_table = \"silver_stock_minutes\"\n","\n","# Merge into existing Delta table or create it if it does not exist\n","if spark.catalog.tableExists(silver_table):\n","    delta_table = DeltaTable.forName(spark, silver_table)\n","    (\n","        delta_table.alias(\"target\")\n","        .merge(\n","            silver_df.alias(\"source\"),\n","            \"target.ticker = source.ticker AND target.timestamp = source.timestamp\"\n","        )\n","        .whenMatchedUpdateAll()\n","        .whenNotMatchedInsertAll()\n","        .execute()\n","    )\n","else:\n","    silver_df.write.format(\"delta\").saveAsTable(silver_table)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"a35ddb27-8658-40d3-83ba-3ae924b369cb","normalized_state":"finished","queued_time":"2026-01-08T20:52:46.3549987Z","session_start_time":"2026-01-08T20:52:46.3560824Z","execution_start_time":"2026-01-08T20:53:01.3659964Z","execution_finish_time":"2026-01-08T20:53:39.7498783Z","parent_msg_id":"4593192c-6cda-4b85-8a87-0ccb0b609dd6"},"text/plain":"StatementMeta(, a35ddb27-8658-40d3-83ba-3ae924b369cb, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1223960-39b0-45d0-83bd-35d456cbca61"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"c376541a-203d-4803-8f9a-a569b1645c00"}],"default_lakehouse":"c376541a-203d-4803-8f9a-a569b1645c00","default_lakehouse_name":"stock_project_lakehouse","default_lakehouse_workspace_id":"1dc9d7e2-e8b4-44ea-abc5-3b0e24119da9"}}},"nbformat":4,"nbformat_minor":5}