{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","from delta.tables import DeltaTable\n","\n","# Load bronze table\n","bronze_df = spark.table(\"bronze_stock_daily\")\n","\n","# create schema and rename columns\n","silver_df = (\n","    bronze_df\n","    .withColumn(\"date\", F.to_date(\"Datetime\"))\n","    .withColumn(\"open\", F.col(\"Open\").cast(\"double\"))\n","    .withColumn(\"high\", F.col(\"High\").cast(\"double\"))\n","    .withColumn(\"low\", F.col(\"Low\").cast(\"double\"))\n","    .withColumn(\"close\", F.col(\"Close\").cast(\"double\"))\n","    .withColumn(\"volume\", F.col(\"Volume\").cast(\"long\"))\n","    .withColumn(\"ticker\", F.col(\"ticker\"))\n",")\n","\n","# Remove original bronze columns AFTER creating new ones\n","silver_df = silver_df.drop(\"Datetime\")\n","\n","# Deduplicate by ticker + date\n","window_spec = Window.partitionBy(\"ticker\", \"date\").orderBy(F.lit(1))\n","\n","silver_df = (\n","    silver_df\n","    .withColumn(\"row_num\", F.row_number().over(window_spec))\n","    .filter(F.col(\"row_num\") == 1)\n","    .drop(\"row_num\")\n",")\n","\n","# Add ingestion timestamp and define final column order \n","silver_df = ( \n","    silver_df \n","    .withColumn(\"ingestion_time\", F.current_timestamp())\n","    .select(\"ticker\", \"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"ingestion_time\") \n",")\n","\n","# Define target table\n","silver_table = \"silver_stock_daily\"\n","\n","# Check if the table already exists in the Lakehouse\n","if spark.catalog.tableExists(silver_table):\n","    delta_table = DeltaTable.forName(spark, silver_table)\n","    (\n","        delta_table.alias(\"target\")\n","        .merge(\n","            silver_df.alias(\"source\"),\n","            \"target.ticker = source.ticker AND target.date = source.date\"\n","        )\n","        .whenMatchedUpdateAll()\n","        .whenNotMatchedInsertAll()\n","        .execute()\n","    )\n","else:\n","    silver_df.write.format(\"delta\").saveAsTable(silver_table)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"c2a78d58-ed77-49c5-a8d0-59a79a424eb6","normalized_state":"finished","queued_time":"2026-01-08T20:50:20.3637221Z","session_start_time":"2026-01-08T20:50:20.3646606Z","execution_start_time":"2026-01-08T20:50:34.950549Z","execution_finish_time":"2026-01-08T20:51:20.3725904Z","parent_msg_id":"570a4664-9433-42b7-a90d-033b39fe1374"},"text/plain":"StatementMeta(, c2a78d58-ed77-49c5-a8d0-59a79a424eb6, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"149ad008-7a17-4ee0-8cbd-bb39e2fafcb8"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"c376541a-203d-4803-8f9a-a569b1645c00"}],"default_lakehouse":"c376541a-203d-4803-8f9a-a569b1645c00","default_lakehouse_name":"stock_project_lakehouse","default_lakehouse_workspace_id":"1dc9d7e2-e8b4-44ea-abc5-3b0e24119da9"}}},"nbformat":4,"nbformat_minor":5}