{"cells":[{"cell_type":"code","source":["from pyspark.sql import functions as F\n","from pyspark.sql.window import Window\n","\n","# Load gold table\n","gold = spark.read.table(\"gold_stock_minutes_indicators\")\n","\n","# Try to load existing dim table\n","try:\n","    dim = spark.read.table(\"dim_trading_minutes\")\n","    dim_exists = True\n","except:\n","    dim_exists = False\n","\n","if dim_exists:\n","    # Get max timestamp from existing dim\n","    max_ts = dim.agg(F.max(\"timestamp\")).collect()[0][0]\n","\n","    # Only new timestamps\n","    new_minutes = (\n","        gold.filter(F.col(\"timestamp\") > max_ts)\n","            .select(\"timestamp\")\n","            .dropDuplicates()\n","    )\n","\n","    # Combine old + new\n","    updated_dim = (\n","        dim.select(\"timestamp\")\n","           .unionByName(new_minutes)\n","           .dropDuplicates([\"timestamp\"])\n","           .orderBy(\"timestamp\")\n","    )\n","\n","else:\n","    # First creation\n","    updated_dim = (\n","        gold.select(\"timestamp\")\n","            .dropna()\n","            .dropDuplicates()\n","            .orderBy(\"timestamp\")\n","    )\n","\n","# Add helper columns\n","updated_dim = (\n","    updated_dim\n","    .withColumn(\"date\", F.to_date(\"timestamp\"))\n","    .withColumn(\"hour\", F.hour(\"timestamp\"))\n","    .withColumn(\"minute\", F.minute(\"timestamp\"))\n",")\n","\n","# Add stable trading_minute_id\n","window_spec = Window.orderBy(\"timestamp\")\n","updated_dim = updated_dim.withColumn(\"trading_minute_id\", F.row_number().over(window_spec))\n","\n","# Save table\n","updated_dim.write.mode(\"overwrite\").saveAsTable(\"dim_trading_minutes\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"state":"finished","livy_statement_state":"available","session_id":"339454e4-b0ec-4934-8d9b-3ebe2ad44eed","normalized_state":"finished","queued_time":"2026-01-12T22:32:56.4740759Z","session_start_time":null,"execution_start_time":"2026-01-12T22:32:56.4751643Z","execution_finish_time":"2026-01-12T22:33:08.4352245Z","parent_msg_id":"bd90c980-ffc3-4e12-8bfd-38650b9a52d5"},"text/plain":"StatementMeta(, 339454e4-b0ec-4934-8d9b-3ebe2ad44eed, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"50a3827b-26a4-4096-af5a-e1b5ebf02a45"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"c376541a-203d-4803-8f9a-a569b1645c00"}],"default_lakehouse":"c376541a-203d-4803-8f9a-a569b1645c00","default_lakehouse_name":"stock_project_lakehouse","default_lakehouse_workspace_id":"1dc9d7e2-e8b4-44ea-abc5-3b0e24119da9"}}},"nbformat":4,"nbformat_minor":5}